{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tutorial](https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.preprocessing import image \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CoronaImages/Chest_xray_Corona_Metadata.csv').drop('Unnamed: 0', axis =1)\n",
    "na_fill = {'VirusCategory1': 'Normal', 'VirusCategory2': 'Normal'}\n",
    "df = df.fillna(value = na_fill).replace('bacteria', 'Bacteria')\n",
    "df.VirusCategory2.unique(), df.VirusCategory1.unique()\n",
    "df = df.join(pd.get_dummies(df.VirusCategory1.values, prefix = 'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_value(path): \n",
    "    img = image.load_img(path, target_size = (28,28,1))\n",
    "    img = image.img_to_array(img)/255\n",
    "    return img \n",
    "\n",
    "def get_train(df): \n",
    "    train_df = df[df.DataType == 'TRAIN']\n",
    "    unique_types = [f'type_{i}' for i in df.VirusCategory1.unique()]\n",
    "    train_labels = train_df[unique_types].values \n",
    "    train_paths = list(map(lambda x: f'CoronaImages/train/{x}', train_df.ImagePath.values))\n",
    "    train_img = []\n",
    "    for path in tqdm(train_paths): \n",
    "        train_img.append(get_image_value(path))\n",
    "    \n",
    "    return dict(Images = np.array(train_img).squeeze(), Labels = train_labels)\n",
    "\n",
    "def get_test(df): \n",
    "    test_df = df[df.DataType == 'TEST']\n",
    "    unique_types = [f'type_{i}' for i in df.VirusCategory1.unique()]\n",
    "    test_labels = test_df[unique_types].values \n",
    "    test_paths = list(map(lambda x: f'CoronaImages/test/{x}', test_df.ImagePath.values))\n",
    "    test_img = []   \n",
    "    for path in tqdm(test_paths): \n",
    "        test_img.append(get_image_value(path))\n",
    "    \n",
    "    return dict(Images = np.array(test_img).squeeze(), Labels = test_labels)\n",
    "    \n",
    "# label_encoder = LabelEncoder().fit(df.VirusCategory1.values)\n",
    "train_dict = get_train(df)\n",
    "test_dict = get_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot = OneHotEncoder().fit(df.VirusCategory1.unique().reshape(1,-1))\n",
    "# label_encoder = LabelEncoder().fit(df.VirusCategory1.values)\n",
    "\n",
    "\n",
    "x_train = train_dict['Images']\n",
    "y_train = train_dict['Labels']\n",
    "x_test = test_dict['Images']\n",
    "y_test = test_dict['Labels']\n",
    "print(x_train[0].shape, x_train.shape, x_test[0].shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Exprimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model(x, y): \n",
    "    drop = .2 \n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape = (28,28,3)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(drop))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('ModelCheckpointWeights.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "model = get_conv_model(x_train, y_train)\n",
    "model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 1, \n",
    "         callbacks = [early_stopping, model_checkpoint], validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.VirusCategory1 == 'COVID-19') & (df.DataType =='TEST')]\n",
    "\n",
    "# test_img = get_image_value('Test.jpeg')\n",
    "# test_predict = model.predict(test_img.reshape(28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "epochs = 5 \n",
    "n_folds = 1 \n",
    "batch_size = 128 \n",
    "\n",
    "model_history =[] \n",
    "pat = 5 \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('fas_mnist_1.h5', verbose=1, save_best_only=True)\n",
    "for i in range(n_folds): \n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_train, y_train, train_size = .85,\n",
    "                                                       random_state = np.random.randint(1, 1000))\n",
    "    model = get_conv_model(train_x, train_y)\n",
    "    results = model.fit(train_x, train_y, epochs = epochs, batch_size = batch_size, \n",
    "                        validation_data = (test_x, test_y), callbacks = [early_stopping, model_checkpoint], \n",
    "                       verbose = 1)\n",
    "    model_history.append(results)\n",
    "    print(f'Finished {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kfold = KFold(n_splits =10, shuffle = True)\n",
    "results = cross_val_score(model, x_test, y_test, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
